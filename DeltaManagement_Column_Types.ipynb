{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7489542-8159-499a-99cb-c7e60ba40d48",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d3a296-02b3-42a7-9ece-59ef2d6a15df",
   "metadata": {},
   "source": [
    "# **DELTA Table Management: Change columns types**\n",
    "\n",
    "#### Overview\n",
    "- This notebook is designed to change a Delta table column name or type\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Functionalities\n",
    "- **Data definition**\n",
    "\n",
    "---\n",
    "\n",
    "#### Prerequisites\n",
    "- **Libraries**: \n",
    "- **Data Sources**: \n",
    "- **Permissions**: \n",
    "\n",
    "---\n",
    "\n",
    "#### Usage Instructions\n",
    "1. **Set Up**: \n",
    "2. **Run Cells**: \n",
    "3. **Modify Parameters**: \n",
    "4. **Save Outputs**: \n",
    "\n",
    "---\n",
    "\n",
    "#### Notes\n",
    "- **Assumptions**:\n",
    "- https://fabric.guru/enabling-column-mapping-for-spaces-in-column-names-in-delta-table\n",
    "- **Limitations**: \n",
    "- **Version**: \n",
    "\n",
    "---\n",
    "\n",
    "#### Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27418c3-ade3-46b4-981a-0475dfcf6db9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "def alter_column_types(\n",
    "    table_name: str,\n",
    "    type_change_dict: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Alter column types of a Delta table using Spark SQL.\n",
    "\n",
    "    Args:\n",
    "        table_name (str): The name of the Delta table.\n",
    "        type_change_dict (dict): Dictionary with {column_name: new_data_type}.\n",
    "                                 E.g. {\"ProjectID\": \"STRING\", \"StartDate\": \"DATE\"}\n",
    "    \"\"\"\n",
    "    for col, new_type in type_change_dict.items():\n",
    "        alter_type_sql = f\"\"\"\n",
    "        ALTER TABLE `{table_name}` ALTER COLUMN `{col}` TYPE {new_type}\n",
    "        \"\"\"\n",
    "        spark.sql(alter_type_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b2f45-a579-4acd-a06b-cd0d58cec0e9",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "table_name = 'dt_opportunity'\n",
    "\n",
    "type_changes  = {\n",
    "    \"Project_ID\": \"STRING\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa1d57-afc2-4f76-8ebf-a16ae7ed3fb2",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "alter_column_types(table_name, type_changes)"
   ]
  }
 ],
 "metadata": {
  "a365ComputeOptions": null,
  "dependencies": {
   "lakehouse": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "sessionKeepAliveTimeout": 0,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
